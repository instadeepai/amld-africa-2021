{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "mava_overview.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MAVA Quickstart Notebook\n",
        "<img src=\"https://raw.githubusercontent.com/instadeepai/Mava/develop/docs/images/mava.png\" />\n",
        "\n",
        "### Guide to installing Mava, creating and training your first Multi-Agent System. \n",
        "\n",
        "For more details about Mava and an overview of its design/features, please visit our [repo](https://github.com/instadeepai/Mava). \n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/instadeepai/amld-africa-2021/blob/main/Part-II/mava_overview.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ],
      "metadata": {
        "id": "8uCEQLS3zZUn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Installation"
      ],
      "metadata": {
        "id": "WEAq7x7ff1fE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Install Mava and Some Supported Environments (Run Cell)\n",
        "%%capture\n",
        "!pip install git+https://github.com/instadeepai/Mava#egg=id-mava[reverb,tf,launchpad,envs]"
      ],
      "outputs": [],
      "metadata": {
        "id": "Pl4ed6X22tZq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Installs and Imports for Agent Visualization (Run Cell)\n",
        "%%capture\n",
        "!pip install git+https://github.com/instadeepai/Mava#egg=id-mava[record_episode]\n",
        "! apt-get update -y &&  apt-get install -y xvfb &&  apt-get install -y python-opengl && apt-get install ffmpeg && apt-get install python-opengl -y && apt install xvfb -y && pip install pyvirtualdisplay \n",
        "\n",
        "import os\n",
        "import IPython\n",
        "from IPython.display import HTML\n",
        "from pyvirtualdisplay import Display\n",
        "import glob\n",
        "\n",
        "\n",
        "display = Display(visible=0, size=(1024, 768))\n",
        "display.start()\n",
        "os.environ[\"DISPLAY\"] = \":\" + str(display.display)"
      ],
      "outputs": [],
      "metadata": {
        "id": "aDYrT7BVw7Dx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Import Modules"
      ],
      "metadata": {
        "id": "7SGFGmWnhuI2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Imports Modules (Run Cell)\n",
        "import functools\n",
        "from datetime import datetime\n",
        "from typing import Any, Dict, Mapping, Sequence, Union\n",
        "\n",
        "import launchpad as lp\n",
        "import numpy as np\n",
        "import sonnet as snt\n",
        "import tensorflow as tf\n",
        "from absl import app, flags\n",
        "from acme import types\n",
        "from mava.components.tf import networks\n",
        "from acme.tf import utils as tf2_utils\n",
        "\n",
        "\n",
        "from mava import specs as mava_specs\n",
        "from mava.utils.enums import ArchitectureType, Network\n",
        "from mava.components.tf.modules.exploration import LinearExplorationScheduler\n",
        "from mava.systems.tf import maddpg, mad4pg, madqn\n",
        "from mava.utils import lp_utils\n",
        "from mava.utils.environments import debugging_utils\n",
        "from mava.wrappers import MonitorParallelEnvironmentLoop\n",
        "from mava.components.tf import architectures\n",
        "from mava.utils.loggers import logger_utils\n",
        "from mava.components.tf.modules.communication.broadcasted import (\n",
        "    BroadcastedCommunication,\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "8SvWrsWExz31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Train a Multi-Agent Reinforcement Learning (MARL) `DDPG` System"
      ],
      "metadata": {
        "id": "Ul_phKL7h4Vq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Agent Networks\n",
        "We will use the default agent networks for the `maddpg` system."
      ],
      "metadata": {
        "id": "l8XqA9M2iyK_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "network_factory = lp_utils.partial_kwargs(\n",
        "    maddpg.make_default_networks,\n",
        "    policy_networks_layer_sizes = (100, ),\n",
        "    critic_networks_layer_sizes = (100, )\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "UJ4-cN2dkXjq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select Environment\n",
        "We will use our [debug environment](https://github.com/instadeepai/Mava#debugging)."
      ],
      "metadata": {
        "id": "ohA5m0REjhu-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "env_name = \"simple_spread\"\n",
        "action_space = \"continuous\"\n",
        "\n",
        "environment_factory = functools.partial(\n",
        "    debugging_utils.make_environment,\n",
        "    env_name=env_name,\n",
        "    action_space=action_space,\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "Fw_4dR1jj-Wv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create MARL System"
      ],
      "metadata": {
        "id": "lcZKJhnyk45C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Specify logging and checkpointing config. "
      ],
      "metadata": {
        "id": "avvSeVahk_Nt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Directory to store checkpoints and log data. \n",
        "base_dir = \"~/mava\"\n",
        "\n",
        "# File name \n",
        "mava_id = datetime.now().strftime(\"DDPG_%Y-%m-%d_%H:%M:%S\")\n",
        "\n",
        "# Log every [log_every] seconds\n",
        "log_every = 15\n",
        "logger_factory = functools.partial(\n",
        "    logger_utils.make_logger,\n",
        "    directory=base_dir,\n",
        "    to_terminal=True,\n",
        "    to_tensorboard=True,\n",
        "    time_stamp=mava_id,\n",
        "    time_delta=log_every,\n",
        ")\n",
        "\n",
        "# Checkpointer appends \"Checkpoints\" to checkpoint_dir\n",
        "checkpoint_dir = f\"{base_dir}/{mava_id}\""
      ],
      "outputs": [],
      "metadata": {
        "id": "u8J05yDlk-ya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create Multi-Agent DDPG System."
      ],
      "metadata": {
        "id": "5i3tj4h-lTm4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "system = maddpg.MADDPG(\n",
        "    environment_factory=environment_factory,\n",
        "    network_factory=network_factory,\n",
        "    logger_factory=logger_factory,\n",
        "    num_executors=1,\n",
        "    policy_optimizer=snt.optimizers.Adam(learning_rate=1e-3),\n",
        "    critic_optimizer=snt.optimizers.Adam(learning_rate=1e-3),\n",
        "    checkpoint_subpath=checkpoint_dir,\n",
        "    max_gradient_norm=40.0,\n",
        "    checkpoint=False,\n",
        "    batch_size=256,\n",
        "\n",
        "    # Record agents in environment. \n",
        "    eval_loop_fn=MonitorParallelEnvironmentLoop,\n",
        "    eval_loop_fn_kwargs={\"path\": checkpoint_dir, \"record_every\": 10, \"fps\": 5},\n",
        ").build()"
      ],
      "outputs": [],
      "metadata": {
        "id": "CS618jAtxM1h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Multi-Agent DDPG System."
      ],
      "metadata": {
        "id": "qBWiibHIleQk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Ensure only trainer runs on gpu, while other processes run on cpu. \n",
        "local_resources = lp_utils.to_device(program_nodes=system.groups.keys())\n",
        "\n",
        "lp.launch(\n",
        "    system,\n",
        "    lp.LaunchType.LOCAL_MULTI_PROCESSING,\n",
        "    terminal=\"output_to_files\",\n",
        "    local_resources=local_resources,\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "gsoLWPTClnMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logs and Outputs"
      ],
      "metadata": {
        "id": "uN2KNO5V11E1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### View outputs from the evaluator process.\n",
        "*You might need to wait a few moments after launching the run.*\n",
        "The `CUDA_ERROR_NO_DEVICE` error is expected since the GPU is only used by the trainer. "
      ],
      "metadata": {
        "id": "JfI2fNFeltBm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!cat /tmp/launchpad_out/evaluator/0"
      ],
      "outputs": [],
      "metadata": {
        "id": "5OchHHlv-dqv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### View Stored Data \n",
        "*You might need to wait a few moments after launching the run.*"
      ],
      "metadata": {
        "id": "XHf3jDe3ySk7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "! ls ~/mava/$mava_id"
      ],
      "outputs": [],
      "metadata": {
        "id": "IPahKjTnqBAO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensorboard\n",
        "*You might need to wait a few moments after launching the run.*"
      ],
      "metadata": {
        "id": "SHygoBPW-3KV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "outputs": [],
      "metadata": {
        "id": "l181SBwtBo9M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To view training results, start tensorboard and filter for the `evaluator/RawEpisodeReturn` tag.\n",
        "\n",
        "A good score is a `RawEpisodeReturn` between 30-40. Although this system is stochastic, it should reach that score atleast by 100 evaluator episodes.    "
      ],
      "metadata": {
        "id": "BJl7LKmHAOk-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%tensorboard --logdir ~/mava/$mava_id/"
      ],
      "outputs": [],
      "metadata": {
        "id": "3fU3yEhdFx1O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### View Agent Recording\n",
        "Once a good score is reached, you can view intelligent multi-agent behaviour by viewing the agent recordings."
      ],
      "metadata": {
        "id": "zDlUXGltyVhM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Check if any agent recordings are available. "
      ],
      "metadata": {
        "id": "-2l8o2zDBbuN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "! ls ~/mava/$mava_id/recordings"
      ],
      "outputs": [],
      "metadata": {
        "id": "HXB1IKfysMT6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### View the latest agent recording. "
      ],
      "metadata": {
        "id": "HjcnXbl7BfJc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the agents are trained (*usually around agents_200_eval...*), they should move to assigned landmarks.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/instadeepai/Mava/develop/docs/images/simple_spread.png\" width=\"250\" height=\"250\" />"
      ],
      "metadata": {
        "id": "WJ33l0uIJ9xB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Recordings\n",
        "list_of_files = glob.glob(f\"/root/mava/{mava_id}/recordings/*.html\")\n",
        "\n",
        "if (list_of_files == 0):\n",
        "  print(\"No recordings are available yet. Please wait or run the 'Run Multi-Agent DDPG System.' cell if you haven't already done this.\")\n",
        "else:\n",
        "  latest_file = max(list_of_files, key=os.path.getctime)\n",
        "  print(\"Running the latest recording.\")\n",
        "\n",
        "# Latest file needs to point to the latest recording\n",
        "IPython.display.HTML(filename=latest_file)"
      ],
      "outputs": [],
      "metadata": {
        "id": "DEEshoXd2K1S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What's next?\n",
        "- Run System with custom agent networks.\n",
        "- Try Different Architectures.\n",
        "- Scaling. \n",
        "- Different Algorithm"
      ],
      "metadata": {
        "id": "KYekMtHB26yL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Kill old run\n",
        "Run this cell when you are ready to move on. Try to let the experiment run for 5-7 minutes before you kill the run."
      ],
      "metadata": {
        "id": "p8f7wKznTMt6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%%capture\n",
        "# Kill old runs. (Run Cell)\n",
        "!ps aux  |  grep -i launchpad  |  awk '{print $2}'  |  xargs sudo kill -9"
      ],
      "outputs": [],
      "metadata": {
        "id": "LE_135VP0I0x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Run System with Custom agent networks\n",
        "Build your own custom networks."
      ],
      "metadata": {
        "id": "YnKx6MRKYYAP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def make_custom_network(environment_spec, agent_net_keys):\n",
        "\n",
        "  \"\"\"Creates networks used by the agents.\"\"\"\n",
        "  specs = environment_spec.get_agent_specs()\n",
        "\n",
        "  # Create agent_type specs\n",
        "  specs = {agent_net_keys[key]: specs[key] for key in specs.keys()}\n",
        "\n",
        "  observation_networks = {}\n",
        "  policy_networks = {}\n",
        "  critic_networks = {}\n",
        "\n",
        "  for agent in specs.keys():\n",
        "    \n",
        "    agent_act_spec = specs[agent].actions\n",
        "\n",
        "    # Get total number of action dimensions from action spec.\n",
        "    num_dimensions = np.prod(agent_act_spec.shape, dtype=int)\n",
        "    \n",
        "    # Create policy network\n",
        "    policy_network = snt.Sequential([\n",
        "        snt.Linear(output_size=256),\n",
        "        tf.nn.relu,\n",
        "        snt.Linear(output_size=num_dimensions),\n",
        "        tf.nn.relu,\n",
        "        networks.TanhToSpec(agent_act_spec)\n",
        "    ])\n",
        "\n",
        "    # Create the critic network.\n",
        "    critic_network = snt.Sequential([\n",
        "         # The multiplexer concatenates the observations/actions.\n",
        "        networks.CriticMultiplexer(),\n",
        "        snt.Linear(output_size=256),\n",
        "        tf.nn.relu,\n",
        "        snt.Linear(output_size=256),\n",
        "        tf.nn.relu,\n",
        "        snt.Linear(1)\n",
        "    ])\n",
        "\n",
        "    # An optional network to process observations\n",
        "    observation_network = tf2_utils.to_sonnet_module(tf.identity)\n",
        "\n",
        "    observation_networks[agent] = observation_network\n",
        "    policy_networks[agent] = policy_network\n",
        "    critic_networks[agent] = critic_network\n",
        "\n",
        "  return {\n",
        "      \"policies\": policy_networks,\n",
        "      \"critics\": critic_networks,\n",
        "      \"observations\": observation_networks,\n",
        "  }\n",
        "\n",
        "# Make network factory\n",
        "network_factory = lp_utils.partial_kwargs(make_custom_network)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "o64UWlhttvl5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup logging\n"
      ],
      "metadata": {
        "id": "l76NFhGkz_8K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Logging config. (Run Cell)\n",
        "# Directory to store checkpoints and log data. \n",
        "base_dir = \"~/mava/\"\n",
        "\n",
        "# File name \n",
        "mava_id = datetime.now().strftime(\"DDPG_Custom_Network_%Y-%m-%d_%H:%M:%S\")\n",
        "\n",
        "# Log every [log_every] seconds\n",
        "log_every = 15\n",
        "logger_factory = functools.partial(\n",
        "    logger_utils.make_logger,\n",
        "    directory=base_dir,\n",
        "    to_terminal=True,\n",
        "    to_tensorboard=True,\n",
        "    time_stamp=mava_id,\n",
        "    time_delta=log_every,\n",
        ")\n",
        "\n",
        "# Checkpointer appends \"Checkpoints\" to checkpoint_dir\n",
        "checkpoint_dir = f\"{base_dir}/{mava_id}\""
      ],
      "outputs": [],
      "metadata": {
        "id": "7SjXoC1RL4uk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run System"
      ],
      "metadata": {
        "id": "a3lGlD9KShpQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Run system with custom networks. (Run Cell)\n",
        "system = maddpg.MADDPG(\n",
        "    environment_factory=environment_factory,\n",
        "    network_factory=network_factory,\n",
        "    logger_factory=logger_factory,\n",
        "    num_executors=1,\n",
        "    policy_optimizer=snt.optimizers.Adam(learning_rate=1e-3),\n",
        "    critic_optimizer=snt.optimizers.Adam(learning_rate=1e-3),\n",
        "    checkpoint_subpath=checkpoint_dir,\n",
        "    max_gradient_norm=40.0,\n",
        "    checkpoint=False,\n",
        ").build()\n",
        "\n",
        "local_resources = lp_utils.to_device(program_nodes=system.groups.keys())\n",
        "\n",
        "lp.launch(\n",
        "    system,\n",
        "    lp.LaunchType.LOCAL_MULTI_PROCESSING,\n",
        "    terminal=\"output_to_files\",\n",
        "    local_resources=local_resources,\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "s-6fwzxxbLIk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### View logs\n",
        "*You might need to wait a few moments after launching the run.*"
      ],
      "metadata": {
        "id": "xepCdLHN0jhA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!cat /tmp/launchpad_out/evaluator/0"
      ],
      "outputs": [],
      "metadata": {
        "id": "qhKKXZiwwG_Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensorboard\n",
        "You might need to wait a few moments after launching the run."
      ],
      "metadata": {
        "id": "VzGIPIbrMn94"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%tensorboard --logdir ~/mava/$mava_id/"
      ],
      "outputs": [],
      "metadata": {
        "id": "OVMrr79dwJax"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Kill old run\n",
        "Run this cell when you are ready to move on. Try to let the experiment run for 5-7 minutes before you kill the run."
      ],
      "metadata": {
        "id": "byLoH9lQTB0E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%%capture\n",
        "# Kill old runs. (Run Cell)\n",
        "!ps aux  |  grep -i launchpad  |  awk '{print $2}'  |  xargs sudo kill -9"
      ],
      "outputs": [],
      "metadata": {
        "id": "7au2jUneMy-k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Try Different Architectures\n",
        "Mava provides several components to support the design of MARL systems such as different system architectures and modules. For more information on different architectures, please have a look at our [components](https://github.com/instadeepai/Mava#components), visit [here](https://github.com/instadeepai/Mava/tree/develop/mava/components/tf/architectures) or view our [examples](https://github.com/instadeepai/Mava/tree/develop/examples).\n"
      ],
      "metadata": {
        "id": "iDkVxBsw00VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup logging"
      ],
      "metadata": {
        "id": "ite8o3CeQfWJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Logging config. (Run Cell)\n",
        "# Directory to store checkpoints and log data. \n",
        "base_dir = \"~/mava/\"\n",
        "\n",
        "# File name \n",
        "mava_id = datetime.now().strftime(\"DDPG_Centralized_%Y-%m-%d_%H:%M:%S\")\n",
        "\n",
        "# Log every [log_every] seconds\n",
        "log_every = 15\n",
        "logger_factory = functools.partial(\n",
        "    logger_utils.make_logger,\n",
        "    directory=base_dir,\n",
        "    to_terminal=True,\n",
        "    to_tensorboard=True,\n",
        "    time_stamp=mava_id,\n",
        "    time_delta=log_every,\n",
        ")\n",
        "\n",
        "# Checkpointer appends \"Checkpoints\" to checkpoint_dir\n",
        "checkpoint_dir = f\"{base_dir}/{mava_id}\""
      ],
      "outputs": [],
      "metadata": {
        "id": "3WV1d8rmMy-l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let try switch from **Decentralised** (default) to **Centralised** architecture. "
      ],
      "metadata": {
        "id": "JoFD5FfuLQhX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run System"
      ],
      "metadata": {
        "id": "ki8-xAmRSpG6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# networks\n",
        "network_factory = lp_utils.partial_kwargs(\n",
        "    maddpg.make_default_networks,\n",
        "    policy_networks_layer_sizes = (100, ),\n",
        "    critic_networks_layer_sizes = (100, )\n",
        ")\n",
        "\n",
        "# distributed program\n",
        "system = maddpg.MADDPG(\n",
        "    environment_factory=environment_factory,\n",
        "    network_factory=network_factory,\n",
        "    logger_factory=logger_factory,\n",
        "    num_executors=1,\n",
        "    policy_optimizer=snt.optimizers.Adam(learning_rate=1e-3),\n",
        "    critic_optimizer=snt.optimizers.Adam(learning_rate=1e-3),\n",
        "    checkpoint_subpath=checkpoint_dir,\n",
        "    max_gradient_norm=40.0,\n",
        "    checkpoint=False,\n",
        "    # Centralised architecture and training. \n",
        "    architecture=architectures.CentralisedQValueCritic,\n",
        "    trainer_fn=maddpg.MADDPGCentralisedTrainer,\n",
        ").build()\n",
        "\n",
        "# Ensure only trainer runs on gpu, while other processes run on cpu. \n",
        "local_resources = lp_utils.to_device(program_nodes=system.groups.keys())\n",
        "\n",
        "lp.launch(\n",
        "    system,\n",
        "    lp.LaunchType.LOCAL_MULTI_PROCESSING,\n",
        "    terminal=\"output_to_files\",\n",
        "    local_resources=local_resources,\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "29bNf4WEpu9H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### View logs\n",
        "*You might need to wait a few moments after launching the run.*"
      ],
      "metadata": {
        "id": "CxFY0WOtNYfJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "cat /tmp/launchpad_out/evaluator/0"
      ],
      "outputs": [],
      "metadata": {
        "id": "piVPE-WuNYfJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensorboard\n",
        "You might need to wait a few moments after launching the run."
      ],
      "metadata": {
        "id": "c3O9mqkINYfJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%tensorboard --logdir ~/mava/$mava_id/"
      ],
      "outputs": [],
      "metadata": {
        "id": "4VCNkcrqNYfJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Kill old run\n",
        "Run this cell when you are ready to move on. Try to let the experiment run for 5-7 minutes before you kill the run."
      ],
      "metadata": {
        "id": "dUv_bI3JS1EE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%%capture\n",
        "# Kill old runs. (Run Cell)\n",
        "!ps aux  |  grep -i launchpad  |  awk '{print $2}'  |  xargs sudo kill -9"
      ],
      "outputs": [],
      "metadata": {
        "id": "mAe8wVIVNnIh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Scaling\n",
        "Mava allows for simple scaling of MARL systems. "
      ],
      "metadata": {
        "id": "5TwjhQ0K4_yd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup logging"
      ],
      "metadata": {
        "id": "p7aI4xQyRA8C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Logging config. (Run Cell)\n",
        "# Directory to store checkpoints and log data. \n",
        "base_dir = \"~/mava/\"\n",
        "\n",
        "# File name \n",
        "mava_id = datetime.now().strftime(\"DDPG_Scaled_%Y-%m-%d_%H:%M:%S\")\n",
        "\n",
        "# Log every [log_every] seconds\n",
        "log_every = 15\n",
        "logger_factory = functools.partial(\n",
        "    logger_utils.make_logger,\n",
        "    directory=base_dir,\n",
        "    to_terminal=True,\n",
        "    to_tensorboard=True,\n",
        "    time_stamp=mava_id,\n",
        "    time_delta=log_every,\n",
        ")\n",
        "\n",
        "# Checkpointer appends \"Checkpoints\" to checkpoint_dir\n",
        "checkpoint_dir = f\"{base_dir}/{mava_id}\""
      ],
      "outputs": [],
      "metadata": {
        "id": "hNJpEGUONnIi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run System\n",
        "Simply increase the **num_executors**. "
      ],
      "metadata": {
        "id": "VEyX2HrBSr1l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# networks\n",
        "network_factory = lp_utils.partial_kwargs(\n",
        "    maddpg.make_default_networks,\n",
        "    policy_networks_layer_sizes = (100, ),\n",
        "    critic_networks_layer_sizes = (100, )\n",
        ")\n",
        "\n",
        "# distributed program\n",
        "system = maddpg.MADDPG(\n",
        "    environment_factory=environment_factory,\n",
        "    network_factory=network_factory,\n",
        "    logger_factory=logger_factory,\n",
        "    # More executors!!\n",
        "    num_executors=4,\n",
        "    policy_optimizer=snt.optimizers.Adam(learning_rate=1e-4),\n",
        "    critic_optimizer=snt.optimizers.Adam(learning_rate=1e-4),\n",
        "    checkpoint_subpath=checkpoint_dir,\n",
        "    max_gradient_norm=40.0,\n",
        "    checkpoint=False,\n",
        ").build()\n",
        "\n",
        "local_resources = lp_utils.to_device(program_nodes=system.groups.keys(),nodes_on_gpu=[\"trainer\"])\n",
        "\n",
        "lp.launch(\n",
        "    system,\n",
        "    lp.LaunchType.LOCAL_MULTI_PROCESSING,\n",
        "    terminal=\"output_to_files\",\n",
        "    local_resources=local_resources,\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "0eD2R8yo5YBf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### View logs\n",
        "*You might need to wait a few moments after launching the run.*"
      ],
      "metadata": {
        "id": "XKne7VqnOI_O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!cat /tmp/launchpad_out/evaluator/0"
      ],
      "outputs": [],
      "metadata": {
        "id": "0tsn_0AzOI_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensorboard\n",
        "You might need to wait a few moments after launching the run."
      ],
      "metadata": {
        "id": "PmkPnQalOI_T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%tensorboard --logdir ~/mava/$mava_id/"
      ],
      "outputs": [],
      "metadata": {
        "id": "G0ttIuwvOI_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Kill old run\n",
        "Run this cell when you are ready to move on. Try to let the experiment run for 5-7 minutes before you kill the run."
      ],
      "metadata": {
        "id": "3wSz4g4dTPez"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%%capture\n",
        "# Kill old runs. (Run Cell)\n",
        "!ps aux  |  grep -i launchpad  |  awk '{print $2}'  |  xargs sudo kill -9"
      ],
      "outputs": [],
      "metadata": {
        "id": "0kYKi1f9TUMv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Use a Different Algorithm\n",
        "Lets experiment with using D4PG instead of DDPG."
      ],
      "metadata": {
        "id": "N3UcNWGVTWVe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup logging"
      ],
      "metadata": {
        "id": "wBKZ1TS-YE8W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Logging config. (Run Cell)\n",
        "# Directory to store checkpoints and log data. \n",
        "base_dir = \"~/mava/\"\n",
        "\n",
        "# File name \n",
        "mava_id = datetime.now().strftime(\"D4PG_%Y-%m-%d_%H:%M:%S\")\n",
        "\n",
        "# Log every [log_every] seconds\n",
        "log_every = 15\n",
        "logger_factory = functools.partial(\n",
        "    logger_utils.make_logger,\n",
        "    directory=base_dir,\n",
        "    to_terminal=True,\n",
        "    to_tensorboard=True,\n",
        "    time_stamp=mava_id,\n",
        "    time_delta=log_every,\n",
        ")\n",
        "\n",
        "# Checkpointer appends \"Checkpoints\" to checkpoint_dir\n",
        "checkpoint_dir = f\"{base_dir}/{mava_id}\""
      ],
      "outputs": [],
      "metadata": {
        "id": "A_h3GKLZYHY5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run System"
      ],
      "metadata": {
        "id": "o5c1jnqSYYKq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Networks\n",
        "network_factory = lp_utils.partial_kwargs(\n",
        "    mad4pg.make_default_networks,\n",
        "    policy_networks_layer_sizes = (100, ),\n",
        "    critic_networks_layer_sizes = (100, )\n",
        ")\n",
        "\n",
        "# D4PG system.\n",
        "system = mad4pg.MAD4PG(\n",
        "    environment_factory=environment_factory,\n",
        "    network_factory=network_factory,\n",
        "    logger_factory=logger_factory,\n",
        "    num_executors=1,\n",
        "    policy_optimizer=snt.optimizers.Adam(learning_rate=1e-3),\n",
        "    critic_optimizer=snt.optimizers.Adam(learning_rate=1e-3),\n",
        "    checkpoint_subpath=checkpoint_dir,\n",
        "    max_gradient_norm=40.0,\n",
        "    checkpoint=False,\n",
        ").build()\n",
        "\n",
        "local_resources = lp_utils.to_device(program_nodes=system.groups.keys())\n",
        "\n",
        "lp.launch(\n",
        "    system,\n",
        "    lp.LaunchType.LOCAL_MULTI_PROCESSING,\n",
        "    terminal=\"output_to_files\",\n",
        "    local_resources=local_resources,\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "vtbSgeAXYmx4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### View logs\n",
        "*You might need to wait a few moments after launching the run.*"
      ],
      "metadata": {
        "id": "t0d4WqPVZVxa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!cat /tmp/launchpad_out/evaluator/0"
      ],
      "outputs": [],
      "metadata": {
        "id": "PqjbCCIGZStC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensorboard\n",
        "You might need to wait a few moments after launching the run."
      ],
      "metadata": {
        "id": "YoP8lrTIZZEb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%tensorboard --logdir ~/mava/$mava_id/"
      ],
      "outputs": [],
      "metadata": {
        "id": "iQ159XIEZcfJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Kill old run\n",
        "Run this cell when you are ready to move on. Try to let the experiment run for 5-7 minutes before you kill the run."
      ],
      "metadata": {
        "id": "H0dcukrJZwWi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%%capture\n",
        "# Kill old runs. (Run Cell)\n",
        "!ps aux  |  grep -i launchpad  |  awk '{print $2}'  |  xargs sudo kill -9"
      ],
      "outputs": [],
      "metadata": {
        "id": "Lx-3oVD0ZtF7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Recurrent MADQN with Comms\n",
        "Finally, lets deploy a recurrent MADQN system with broadcast communication channels between all the agents. This is definetly overboard for such a simple environment, but I think it is worthwhile to see how to deploy such a system in Mava."
      ],
      "metadata": {
        "id": "7bPGKBbuQs_a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup Environment\n",
        "We have been using the continuous action-space debug environment but DQN only works on discrete action-space environments. Luckily Mava has a discrete version of the debug environment, so lets deploy that quickly."
      ],
      "metadata": {
        "id": "oTd65tfffX4B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "env_name = \"simple_spread\"\n",
        "action_space = \"discrete\"\n",
        "\n",
        "environment_factory = functools.partial(\n",
        "    debugging_utils.make_environment,\n",
        "    env_name=env_name,\n",
        "    action_space=action_space,\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "vPVrgr22gLaX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup logging"
      ],
      "metadata": {
        "id": "eQ-KnX_VRNVI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "### Setup Logging\n",
        "# Logging config. (Run Cell)\n",
        "# Directory to store checkpoints and log data. \n",
        "base_dir = \"~/mava/\"\n",
        "\n",
        "# File name \n",
        "mava_id = datetime.now().strftime(\"Rec_MADQN_Comms_%Y-%m-%d_%H:%M:%S\")\n",
        "\n",
        "# Log every [log_every] seconds\n",
        "log_every = 15\n",
        "logger_factory = functools.partial(\n",
        "    logger_utils.make_logger,\n",
        "    directory=base_dir,\n",
        "    to_terminal=True,\n",
        "    to_tensorboard=True,\n",
        "    time_stamp=mava_id,\n",
        "    time_delta=log_every,\n",
        ")\n",
        "\n",
        "# Checkpointer appends \"Checkpoints\" to checkpoint_dir\n",
        "checkpoint_dir = f\"{base_dir}/{mava_id}\""
      ],
      "outputs": [],
      "metadata": {
        "id": "IFu7T5hfSojp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run System"
      ],
      "metadata": {
        "id": "ZOjpLCm0Sp1-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Networks.\n",
        "network_factory = lp_utils.partial_kwargs(\n",
        "    madqn.make_default_networks,\n",
        "    policy_networks_layer_sizes=(100,),\n",
        "    archecture_type=ArchitectureType.recurrent,\n",
        "    message_size=2,\n",
        "    network_type=Network.coms_network,\n",
        ")\n",
        "\n",
        "# Distributed system.\n",
        "system = madqn.MADQN(\n",
        "    environment_factory=environment_factory,\n",
        "    network_factory=network_factory,\n",
        "    logger_factory=logger_factory,\n",
        "    num_executors=1,\n",
        "    exploration_scheduler_fn=LinearExplorationScheduler,\n",
        "    epsilon_min=0.05,\n",
        "    epsilon_decay=5e-4,\n",
        "    batch_size=64,\n",
        "    optimizer=snt.optimizers.Adam(learning_rate=1e-3),\n",
        "    checkpoint_subpath=checkpoint_dir,\n",
        "    # Recurrent Trainer and Executor!!\n",
        "    trainer_fn=madqn.training.MADQNRecurrentCommTrainer,\n",
        "    executor_fn=madqn.execution.MADQNRecurrentCommExecutor,\n",
        "    # Communication Module!! \n",
        "    communication_module=BroadcastedCommunication,\n",
        ").build()\n",
        "\n",
        "local_resources = lp_utils.to_device(program_nodes=system.groups.keys())\n",
        "\n",
        "# Launch the program.h\n",
        "lp.launch(\n",
        "    system,\n",
        "    lp.LaunchType.LOCAL_MULTI_PROCESSING,\n",
        "    terminal=\"output_to_files\",\n",
        "    local_resources=local_resources,\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "O7bwuBFuSuex"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### View logs\n",
        "*You might need to wait a few moments after launching the run.*"
      ],
      "metadata": {
        "id": "-gENz-GPgeQs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!cat /tmp/launchpad_out/evaluator/0"
      ],
      "outputs": [],
      "metadata": {
        "id": "KQRY6F-QghXP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensorboad\n",
        "*You might need to wait a few moments after launching the run.*"
      ],
      "metadata": {
        "id": "e-Fp02iFgoHV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%tensorboard --logdir ~/mava/$mava_id/"
      ],
      "outputs": [],
      "metadata": {
        "id": "7ka7otvHgux2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Comparing All of Our Runs\n",
        "Lets plot all of our runs together to compare their performance."
      ],
      "metadata": {
        "id": "P3HZzBWMbaFN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensorboard\n"
      ],
      "metadata": {
        "id": "2bW5R84JbrFu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%tensorboard --logdir ~/mava/"
      ],
      "outputs": [],
      "metadata": {
        "id": "G_pog8fbbu2x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For more examples using different systems, environments and architectures, visit our [github page](https://github.com/instadeepai/Mava/tree/develop/examples)."
      ],
      "metadata": {
        "id": "_PmsI_-55Y9p"
      }
    }
  ]
}