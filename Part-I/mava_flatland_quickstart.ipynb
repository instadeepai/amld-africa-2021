{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "mava_flatland_quickstart.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.6 64-bit ('amld-africa': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "387b1f301009f9723dfa35a9cccd42028feb98fc75e8e1b000782e327d023209"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MAVA Quickstart Notebook\n",
        "<img src=\"https://raw.githubusercontent.com/instadeepai/Mava/develop/docs/images/mava.png\" />\n",
        "\n",
        "### Guide to installing Mava, creating and training your first Multi-Agent System on Flatland. \n",
        "\n",
        "For more details about Mava and an overview of its design/features, please visit our [repo](https://github.com/instadeepai/Mava). \n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/instadeepai/amld-africa-2021/blob/main/Part-I/mava_flatland_quickstart.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ],
      "metadata": {
        "id": "8uCEQLS3zZUn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Installation"
      ],
      "metadata": {
        "id": "WEAq7x7ff1fE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#@title Install Mava and Some Supported Environments (Run Cell)\n",
        "%%capture\n",
        "!pip install git+https://github.com/instadeepai/Mava#egg=id-mava[reverb,tf,launchpad,envs]"
      ],
      "outputs": [],
      "metadata": {
        "id": "Pl4ed6X22tZq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#@title Installs and Imports for Agent Visualization (Run Cell)\n",
        "%%capture\n",
        "! pip install git+https://github.com/instadeepai/Mava#egg=id-mava[record_episode]\n",
        "! apt-get update -y &&  apt-get install -y xvfb &&  apt-get install -y python-opengl && apt-get install ffmpeg && apt-get install python-opengl -y && apt install xvfb -y && pip install pyvirtualdisplay \n",
        "\n",
        "import os\n",
        "from IPython.display import HTML\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "display = Display(visible=0, size=(1024, 768))\n",
        "display.start()\n",
        "os.environ[\"DISPLAY\"] = \":\" + str(display.display)"
      ],
      "outputs": [],
      "metadata": {
        "id": "aDYrT7BVw7Dx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#@title Install Flatland (Run Cell)\n",
        "%%capture\n",
        "!pip install flatland-rl"
      ],
      "outputs": [],
      "metadata": {
        "id": "CFxCZKDEkGNr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Import Modules"
      ],
      "metadata": {
        "id": "7SGFGmWnhuI2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#@title Imports Modules (Run Cell)\n",
        "import functools\n",
        "from datetime import datetime\n",
        "from typing import Any, Dict, Mapping, Sequence, Union\n",
        "\n",
        "import glob\n",
        "import os \n",
        "import IPython\n",
        "\n",
        "import launchpad as lp\n",
        "import numpy as np\n",
        "import sonnet as snt\n",
        "import tensorflow as tf\n",
        "from absl import app, flags\n",
        "from acme import types\n",
        "from mava.components.tf import networks\n",
        "from acme.tf import utils as tf2_utils\n",
        "\n",
        "from flatland.envs.observations import TreeObsForRailEnv\n",
        "from flatland.envs.predictions import ShortestPathPredictorForRailEnv\n",
        "from flatland.envs.rail_generators import sparse_rail_generator\n",
        "from flatland.envs.schedule_generators import sparse_schedule_generator\n",
        "\n",
        "from mava import specs as mava_specs\n",
        "from mava.systems.tf import madqn\n",
        "from mava.utils import lp_utils\n",
        "from mava.utils.environments.flatland_utils import flatland_env_factory\n",
        "from mava.wrappers import MonitorParallelEnvironmentLoop\n",
        "from mava.components.tf import architectures\n",
        "from mava.utils.loggers import logger_utils\n",
        "from mava.components.tf.modules.exploration.exploration_scheduling import (\n",
        "    LinearExplorationScheduler,\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "8SvWrsWExz31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Launch a Multi-Agent Reinforcement Learning (MARL) `DQN` System"
      ],
      "metadata": {
        "id": "Ul_phKL7h4Vq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Agent Networks\n",
        "We will use the default agent networks for the `madqn` system, a simple feedforward neural network with one hidden layer with 128 hidden neurons."
      ],
      "metadata": {
        "id": "l8XqA9M2iyK_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "network_factory = lp_utils.partial_kwargs(\n",
        "    madqn.make_default_networks,\n",
        "    policy_networks_layer_sizes=(128,)\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "UJ4-cN2dkXjq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select Environment\n",
        "We will use Flatland with the following configs:\n",
        "* 3 trains\n",
        "* The width and height of the map are 25.\n",
        "* Infrastructure generated with the `sparse rail generator`. The infrastructure consists of cities, each composed of maximum 3 rails, and they are interconnected with maximum 2 rails.\n",
        "* Scenario generated with the `sparse schedule generator`. It produces tasks for the agents by selecting a starting city and a target city.\n",
        "* Tree observation with a `max_depth` for exploring the branches.\n",
        "\n",
        "<img src=\"https://i.imgur.com/sGBBhzJ.png\">\n"
      ],
      "metadata": {
        "id": "ohA5m0REjhu-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# flatland environment config\n",
        "rail_gen_cfg: Dict = {\n",
        "    \"max_num_cities\": 3,\n",
        "    \"max_rails_between_cities\": 2,\n",
        "    \"max_rails_in_city\": 3,\n",
        "    \"grid_mode\": True,\n",
        "    \"seed\": 0,\n",
        "}\n",
        "\n",
        "flatland_env_config: Dict = {\n",
        "    \"number_of_agents\": 3,\n",
        "    \"width\": 25,\n",
        "    \"height\": 25,\n",
        "    \"rail_generator\": sparse_rail_generator(**rail_gen_cfg),\n",
        "    \"schedule_generator\": sparse_schedule_generator(),\n",
        "    \"obs_builder_object\": TreeObsForRailEnv(\n",
        "        max_depth=2, predictor=ShortestPathPredictorForRailEnv()\n",
        "    ),\n",
        "}\n",
        "\n",
        "environment_factory = functools.partial(\n",
        "     flatland_env_factory, env_config=flatland_env_config, include_agent_info=False\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "Fw_4dR1jj-Wv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Specify Logging and Checkpointing \n",
        "We will log to Tensorboard so that we can monitor the training progress. "
      ],
      "metadata": {
        "id": "avvSeVahk_Nt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Directory to store checkpoints and log data. \n",
        "base_dir = \"~/mava\"\n",
        "\n",
        "# File name \n",
        "mava_id = datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
        "\n",
        "# Log every [log_every] seconds\n",
        "log_every = 10\n",
        "logger_factory = functools.partial(\n",
        "    logger_utils.make_logger,\n",
        "    directory=base_dir,\n",
        "    to_terminal=True,\n",
        "    to_tensorboard=True,\n",
        "    time_stamp=mava_id,\n",
        "    time_delta=log_every,\n",
        ")\n",
        "\n",
        "# Checkpointer appends \"Checkpoints\" to checkpoint_dir\n",
        "checkpoint_dir = f\"{base_dir}/{mava_id}\""
      ],
      "outputs": [],
      "metadata": {
        "id": "u8J05yDlk-ya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the Multi-Agent DQN System."
      ],
      "metadata": {
        "id": "5i3tj4h-lTm4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "system = madqn.MADQN(\n",
        "    environment_factory=environment_factory,\n",
        "    network_factory=network_factory,\n",
        "    logger_factory=logger_factory,\n",
        "    num_executors=2,\n",
        "    exploration_scheduler_fn=LinearExplorationScheduler,\n",
        "    epsilon_min=0.05,\n",
        "    epsilon_decay=3e-4,\n",
        "    max_replay_size=100_000,\n",
        "    executor_variable_update_period = 100,\n",
        "    # NOTE (Claude) Toggle this line on/off to control add/remove prioritized experience replay\n",
        "    # importance_sampling_exponent=0.2,\n",
        "    optimizer=snt.optimizers.Adam(learning_rate=1e-2),\n",
        "    checkpoint=True,\n",
        "    batch_size=256,\n",
        "    # Record agents in environment. \n",
        "    eval_loop_fn=MonitorParallelEnvironmentLoop,\n",
        "    eval_loop_fn_kwargs={\"path\": checkpoint_dir, \"record_every\": 10, \"fps\": 5},\n",
        ").build()"
      ],
      "outputs": [],
      "metadata": {
        "id": "CS618jAtxM1h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Launch the Distributed Program"
      ],
      "metadata": {
        "id": "qBWiibHIleQk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Ensure only trainer runs on gpu, while other processes run on cpu. \n",
        "local_resources = lp_utils.to_device(program_nodes=system.groups.keys(),nodes_on_gpu=[\"trainer\"])\n",
        "\n",
        "lp.launch(\n",
        "    system,\n",
        "    lp.LaunchType.LOCAL_MULTI_PROCESSING,\n",
        "    terminal=\"output_to_files\",\n",
        "    local_resources=local_resources,\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "gsoLWPTClnMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Logs and Outputs"
      ],
      "metadata": {
        "id": "uN2KNO5V11E1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### View outputs from the evaluator process.\n",
        "*You might need to wait a few moments after launching the run.*\n",
        "The `CUDA_ERROR_NO_DEVICE` error is expected since the GPU is only used by the trainer. "
      ],
      "metadata": {
        "id": "JfI2fNFeltBm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!cat /tmp/launchpad_out/evaluator/0"
      ],
      "outputs": [],
      "metadata": {
        "id": "5OchHHlv-dqv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### View Stored Data \n",
        "*You might need to wait a few moments after launching the run.*\n",
        "You should see a directory for `tensorboard` logs and another directory for storing `recordings` of the agents."
      ],
      "metadata": {
        "id": "XHf3jDe3ySk7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "! ls ~/mava/$mava_id"
      ],
      "outputs": [],
      "metadata": {
        "id": "IPahKjTnqBAO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensorboard\n",
        "*You might need to wait a few moments after launching the run.*"
      ],
      "metadata": {
        "id": "SHygoBPW-3KV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "outputs": [],
      "metadata": {
        "id": "l181SBwtBo9M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To view training results, start tensorboard and filter for the `RawEpisodeReturn` tag.   "
      ],
      "metadata": {
        "id": "BJl7LKmHAOk-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%tensorboard --logdir ~/mava/"
      ],
      "outputs": [],
      "metadata": {
        "id": "3fU3yEhdFx1O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### View Agent Recording\n",
        "Once a good score is reached, you can view intelligent multi-agent behaviour by viewing the agent recordings."
      ],
      "metadata": {
        "id": "zDlUXGltyVhM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### First check if any agent recordings are available.\n",
        "If no entries like `agents_11_eval_episode.html` appear below, then just wait a few more moments before trying again."
      ],
      "metadata": {
        "id": "-2l8o2zDBbuN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "! ls ~/mava/$mava_id/recordings"
      ],
      "outputs": [],
      "metadata": {
        "id": "HXB1IKfysMT6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Choose an agent recording to view. \n",
        "You can set the varaible `RECORDING_NAME` in the cell below to any of the file names that appeared in the list above to view a specific recording eg. `agents_11_eval_episode.html`. If an invalid file is given, then we will try to chose the latest recording for you."
      ],
      "metadata": {
        "id": "HjcnXbl7BfJc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "RECORDING_NAME = \"agents_11_eval_episode.html\"\n",
        "\n",
        "# Check if valid path\n",
        "latest_file = glob.glob(f\"/root/mava/{mava_id}/recordings/{RECORDING_NAME}\")\n",
        "\n",
        "# If we found a file.\n",
        "if len(latest_file) != 0:\n",
        "    latest_file = latest_file[0]\n",
        "    print(\"Running user defined recording.\")\n",
        "else:\n",
        "  # Try get list of all recordings.\n",
        "  list_of_files = glob.glob(f\"/root/mava/{mava_id}/recordings/*.html\")\n",
        "\n",
        "  if(len(list_of_files) == 0):\n",
        "    print(\"No recordings are available yet. Please wait or run the 'Run Multi-Agent MADQN System.' cell if you haven't already done this.\")\n",
        "  else:\n",
        "    # Chose the latest recording.\n",
        "    latest_file = max(list_of_files, key=os.path.getctime)\n",
        "    print(\"Running latest recording.\")\n",
        "\n",
        "# Display the recording.\n",
        "IPython.display.HTML(filename=latest_file)"
      ],
      "outputs": [],
      "metadata": {
        "id": "DEEshoXd2K1S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Kill the Launchpad Program\n",
        "When you are done training your DQN system or would like to restart a run, you can run the cell below to kill the Launchpad process."
      ],
      "metadata": {
        "id": "8XkhlVpTF24R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Kill old runs. (Run Cell)\n",
        "%%capture\n",
        "!ps aux  |  grep -i launchpad  |  awk '{print $2}'  |  xargs sudo kill -9"
      ],
      "outputs": [],
      "metadata": {
        "id": "7au2jUneMy-k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For more examples using different systems, environments and architectures, visit our [github page](https://github.com/instadeepai/Mava/tree/develop/examples)."
      ],
      "metadata": {
        "id": "_PmsI_-55Y9p"
      }
    }
  ]
}